{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9e0bba-b79e-4325-bfe3-f82bf41f7811",
   "metadata": {},
   "source": [
    "# Build XGB using GNN embeddings\n",
    "In this notebook we build a simple GNN model and combine it with XGB model to see if GNN improves XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711e5b1-0f28-471f-b889-1cd46fc4c735",
   "metadata": {},
   "source": [
    "# Simple GNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401f6dcc-853f-49f9-a70e-ccc18deb1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"7\")\n",
    "\n",
    "LOAD = 2\n",
    "VER=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba98df61-5aac-44e3-9c8f-12c1e5d0a1ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SAGEConv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch_geometric/__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtyping\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m, is_compiling\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01m_onnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_in_onnx_export, safe_onnx_export\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch_geometric/typing.py:24\u001b[39m\n\u001b[32m     21\u001b[39m WITH_PT113 = WITH_PT20 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(torch.__version__.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m1\u001b[39m]) >= \u001b[32m13\u001b[39m\n\u001b[32m     23\u001b[39m WITH_WINDOWS = os.name == \u001b[33m'\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m NO_MKL = \u001b[33m'\u001b[39m\u001b[33mUSE_MKL=OFF\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__config__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m WITH_WINDOWS\n\u001b[32m     26\u001b[39m MAX_INT64 = torch.iinfo(torch.int64).max\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m WITH_PT20:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/__config__.py:9\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mshow\u001b[39m() -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    Return a human-readable string with descriptions of the\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    configuration of PyTorch.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_show_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02213d78-7c61-4579-ab9d-f95921d44167",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_features = pd.read_parquet(f\"../data/author_features_v{LOAD}.pqt\")\n",
    "author_targets = pd.read_parquet(f\"../data/author_targets_v{LOAD}.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852e8aa-82c1-4e65-aef5-84edac567a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_ID</th>\n",
       "      <th>target</th>\n",
       "      <th>coauthor_ids</th>\n",
       "      <th>coauthor_counts</th>\n",
       "      <th>coauthor_time_delta</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1461, 1461, 1461, 1461, 1461, 1461, 1461]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1461, 1461, 1461, 1461, 1461, 1461, 1461]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1461, 1461, 1461, 1461, 1461, 1461, 1461]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 2905, 2819, 2906, 2907, ...</td>\n",
       "      <td>[1, 1, 1, 4, 4, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, ...</td>\n",
       "      <td>[1461, 1461, 1461, 761, 761, 1461, 1461, 1013,...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Author_ID  target                                       coauthor_ids  \\\n",
       "0          0       0                                                 []   \n",
       "1          1       0                              [2, 3, 4, 5, 6, 7, 8]   \n",
       "2          2       0                              [1, 3, 4, 5, 6, 7, 8]   \n",
       "3          3       0                              [1, 2, 4, 5, 6, 7, 8]   \n",
       "4          4       1  [1, 2, 3, 5, 6, 7, 8, 2905, 2819, 2906, 2907, ...   \n",
       "\n",
       "                                     coauthor_counts  \\\n",
       "0                                                 []   \n",
       "1                              [1, 1, 1, 1, 1, 1, 1]   \n",
       "2                              [1, 1, 1, 1, 1, 1, 1]   \n",
       "3                              [1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 4, 4, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, ...   \n",
       "\n",
       "                                 coauthor_time_delta  degree  \n",
       "0                                                 []       0  \n",
       "1         [1461, 1461, 1461, 1461, 1461, 1461, 1461]       7  \n",
       "2         [1461, 1461, 1461, 1461, 1461, 1461, 1461]       7  \n",
       "3         [1461, 1461, 1461, 1461, 1461, 1461, 1461]       7  \n",
       "4  [1461, 1461, 1461, 761, 761, 1461, 1461, 1013,...      38  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbcf42-a74e-4ec0-8310-9803549f7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(author_features)\n",
    "assert author_features[\"Author_ID\"].is_unique\n",
    "\n",
    "id2idx = pd.Series(np.arange(N), index=author_features[\"Author_ID\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa8132-b791-4d87-8777-1ef826b2fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG TRANSFORM FOR NN\n",
    "for c in [\n",
    "    \"n_coauthors\",\n",
    "    \"total_collaborations\",\n",
    "    \"total_papers\",\n",
    "    \"total_citations\",\n",
    "    \"citations_last_3y\",\n",
    "    \"max_citations_single_paper\",\n",
    "]:\n",
    "    author_features[f\"log_{c}\"] = np.log1p(author_features[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c44f22-5cd7-49bf-ba1a-1e9159d3660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['n_coauthors', 'total_collaborations', 'avg_collab_strength', 'max_collab_strength', 'collab_entropy', 'total_papers', 'papers_last_1y', 'papers_last_3y', 'days_since_last_paper', 'top_category_frac', 'category_entropy', 'total_citations', 'avg_citations_per_paper', 'max_citations_single_paper', 'citations_last_3y', 'log_n_coauthors', 'log_total_collaborations', 'log_total_papers', 'log_total_citations', 'log_citations_last_3y', 'log_max_citations_single_paper']\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"target\"\n",
    "\n",
    "BASE_FEATURES = [\n",
    "    # --------------------\n",
    "    # Collaboration graph\n",
    "    # --------------------\n",
    "    \"n_coauthors\",\n",
    "    \"total_collaborations\",\n",
    "    \"avg_collab_strength\",\n",
    "    \"max_collab_strength\",\n",
    "    \"collab_entropy\",\n",
    "\n",
    "    # --------------------\n",
    "    # Productivity / recency\n",
    "    # --------------------\n",
    "    \"total_papers\",\n",
    "    \"papers_last_1y\",\n",
    "    \"papers_last_3y\",\n",
    "    \"days_since_last_paper\",\n",
    "\n",
    "    # --------------------\n",
    "    # Topic specialization\n",
    "    # --------------------\n",
    "    #\"top_category\",          # categorical-as-ordinal (needs encoding for NN)\n",
    "    \"top_category_frac\",\n",
    "    \"category_entropy\",\n",
    "\n",
    "    # --------------------\n",
    "    # Citation impact\n",
    "    # --------------------\n",
    "    \"total_citations\",\n",
    "    \"avg_citations_per_paper\",\n",
    "    \"max_citations_single_paper\",\n",
    "    \"citations_last_3y\",\n",
    "]\n",
    "\n",
    "EXTRA_FEATURES = [\n",
    "    \"log_n_coauthors\",\n",
    "    \"log_total_collaborations\",\n",
    "    \"log_total_papers\",\n",
    "    \"log_total_citations\",\n",
    "    \"log_citations_last_3y\",\n",
    "    \"log_max_citations_single_paper\",\n",
    "]\n",
    "\n",
    "FEATURES = [c for c in (BASE_FEATURES + EXTRA_FEATURES) if c in author_features.columns]\n",
    "print(\"Using features:\", FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83186e65-9524-420f-bd46-48e706fe101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = author_features[FEATURES].astype(np.float32).values\n",
    "y = author_features[TARGET].astype(np.int64).values\n",
    "\n",
    "# standardize\n",
    "X_mean = X.mean(axis=0, keepdims=True)\n",
    "X_std  = X.std(axis=0, keepdims=True) + 1e-6\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "x = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4982109-f4ff-4fad-9d3e-f9fe76e4b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Make sure coauthor lists align to author_features order\n",
    "author_targets_aligned = author_targets.set_index(\"Author_ID\").loc[author_features[\"Author_ID\"]].reset_index()\n",
    "\n",
    "src_list = []\n",
    "dst_list = []\n",
    "w_list   = []\n",
    "\n",
    "for i, (co_ids, co_cts) in enumerate(\n",
    "    zip(author_targets_aligned[\"coauthor_ids\"], author_targets_aligned[\"coauthor_counts\"])\n",
    "):\n",
    "    # skip isolated authors\n",
    "    if len(co_ids) == 0:\n",
    "        continue\n",
    "\n",
    "    js = id2idx.loc[co_ids].values.astype(np.int64)\n",
    "    cts = np.asarray(co_cts, dtype=np.float32)\n",
    "\n",
    "    src_list.append(np.full(len(js), i, dtype=np.int64))\n",
    "    dst_list.append(js)\n",
    "    w_list.append(cts)\n",
    "\n",
    "src = np.concatenate(src_list) if src_list else np.empty(0, dtype=np.int64)\n",
    "dst = np.concatenate(dst_list) if dst_list else np.empty(0, dtype=np.int64)\n",
    "w   = np.concatenate(w_list)   if w_list   else np.empty(0, dtype=np.float32)\n",
    "\n",
    "edge_index = torch.tensor(np.vstack([src, dst]), dtype=torch.long)\n",
    "edge_weight = torch.tensor(w, dtype=torch.float)\n",
    "\"\"\"\n",
    "# Make sure coauthor lists align to author_features order\n",
    "author_targets_aligned = author_targets.set_index(\"Author_ID\").loc[author_features[\"Author_ID\"]].reset_index()\n",
    "\n",
    "src_list = []\n",
    "dst_list = []\n",
    "edge_attr_list = [] # Changed from w_list to edge_attr_list\n",
    "\n",
    "# Iterate over coauthor_ids, counts, AND time_deltas\n",
    "# Ensure 'coauthor_time_delta' exists in your dataframe!\n",
    "for i, (co_ids, co_cts, co_times) in enumerate(\n",
    "    zip(\n",
    "        author_targets_aligned[\"coauthor_ids\"], \n",
    "        author_targets_aligned[\"coauthor_counts\"],\n",
    "        author_targets_aligned[\"coauthor_time_delta\"] # New Column\n",
    "    )\n",
    "):\n",
    "    # skip isolated authors\n",
    "    if len(co_ids) == 0:\n",
    "        continue\n",
    "\n",
    "    js = id2idx.loc[co_ids].values.astype(np.int64)\n",
    "    \n",
    "    # Process edge features\n",
    "    cts = np.asarray(co_cts, dtype=np.float32)\n",
    "    times = np.asarray(co_times, dtype=np.float32)\n",
    "    \n",
    "    # Log transform features to stabilize training (recommended)\n",
    "    cts_log = np.log1p(cts)\n",
    "    times_log = np.log1p(times)\n",
    "    \n",
    "    # Stack features to create [num_edges, 2] matrix\n",
    "    edge_features = np.stack([cts_log, times_log], axis=1)\n",
    "\n",
    "    src_list.append(np.full(len(js), i, dtype=np.int64))\n",
    "    dst_list.append(js)\n",
    "    edge_attr_list.append(edge_features)\n",
    "\n",
    "src = np.concatenate(src_list) if src_list else np.empty(0, dtype=np.int64)\n",
    "dst = np.concatenate(dst_list) if dst_list else np.empty(0, dtype=np.int64)\n",
    "\n",
    "# Create 2D edge attributes instead of 1D weights\n",
    "edge_attr = np.concatenate(edge_attr_list) if edge_attr_list else np.empty((0, 2), dtype=np.float32)\n",
    "\n",
    "edge_index = torch.tensor(np.vstack([src, dst]), dtype=torch.long)\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74fd37b-4d6d-4e8f-9a11-14e98d359388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num nodes: 143691\n",
      "Num edges (directed): 11182120\n"
     ]
    }
   ],
   "source": [
    "print(\"Num nodes:\", N)\n",
    "print(\"Num edges (directed):\", edge_index.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a8745-a02e-4129-a67f-348b1ef88680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "data.edge_attr = edge_attr  # Assign the 2D features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TransformerConv\n",
    "\n",
    "class EdgeGAT(torch.nn.Module): # Class name kept same for compatibility\n",
    "    def __init__(self, in_dim, hidden_dim=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Switch to TransformerConv to handle edge_dim=2\n",
    "        self.conv1 = TransformerConv(in_dim, hidden_dim, edge_dim=2)\n",
    "        self.conv2 = TransformerConv(hidden_dim, hidden_dim, edge_dim=2)\n",
    "        self.lin   = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, return_emb=False):\n",
    "        # Pass edge_attr to the conv layers\n",
    "        h = self.conv1(x, edge_index, edge_attr)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        h = self.conv2(h, edge_index, edge_attr)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        if return_emb:\n",
    "            return h\n",
    "\n",
    "        out = self.lin(h).squeeze(-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91fccd-cfeb-4150-be47-714acfe39530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.lin   = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, return_emb=False):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        if return_emb:\n",
    "            return h\n",
    "\n",
    "        out = self.lin(h).squeeze(-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf992892-9326-48cb-9b6a-37779886e5f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = data.to(device)\n",
    "\n",
    "N_SPLITS = 5\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "N = data.num_nodes\n",
    "EMB_DIM = 128\n",
    "\n",
    "# OOF storage (optional, for diagnostics)\n",
    "oof_gnn = np.zeros(N, dtype=np.float32)\n",
    "oof_embs  = np.zeros((N, EMB_DIM), dtype=np.float32)\n",
    "\n",
    "fold_aucs   = []\n",
    "fold_states = []        \n",
    "fold_splits = []        \n",
    "\n",
    "def train_one_fold(train_idx, val_idx, epochs=300, lr=5e-3, wd=1e-4):\n",
    "    \"\"\"\n",
    "    model = GraphSAGE(\n",
    "        in_dim=data.x.size(1),\n",
    "        hidden_dim=EMB_DIM,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \"\"\"\n",
    "    model = EdgeGAT(\n",
    "        in_dim=data.x.size(1),\n",
    "        hidden_dim=EMB_DIM,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    train_mask = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "    val_mask   = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "    train_mask[torch.tensor(train_idx, device=device)] = True\n",
    "    val_mask[torch.tensor(val_idx, device=device)] = True\n",
    "\n",
    "    y_float = data.y.float()\n",
    "\n",
    "    best_auc = -1.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        \"\"\"\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        \"\"\"\n",
    "        logits = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            logits[train_mask],\n",
    "            y_float[train_mask]\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # validation AUC\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_probs = torch.sigmoid(logits[val_mask]).cpu().numpy()\n",
    "            val_true  = data.y[val_mask].cpu().numpy()\n",
    "            auc = roc_auc_score(val_true, val_probs)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_state = {\n",
    "                k: v.detach().cpu().clone()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "\n",
    "        if epoch % 30 == 0 or epoch == 1:\n",
    "            print(\n",
    "                f\"  epoch {epoch:3d} | \"\n",
    "                f\"loss {loss.item():.4f} | \"\n",
    "                f\"val AUC {auc:.5f} | \"\n",
    "                f\"best {best_auc:.5f}\"\n",
    "            )\n",
    "\n",
    "    # restore best model\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \"\"\"logits = model(data.x, data.edge_index)\"\"\"\n",
    "        logits = model(data.x, data.edge_index, data.edge_attr)\n",
    "        val_probs = torch.sigmoid(logits[val_mask]).cpu().numpy()\n",
    "\n",
    "        \"\"\"emb = model(data.x, data.edge_index, return_emb=True)\"\"\"\n",
    "        emb = model(data.x, data.edge_index, data.edge_attr, return_emb=True)\n",
    "        val_emb = emb[val_mask].cpu().numpy()\n",
    "\n",
    "    return best_auc, best_state, val_probs, val_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2f785-a136-433f-9c72-5e323fee31d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### FOLD 1 #####\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(N)), 1):\n",
    "    print(f\"\\n##### FOLD {fold} #####\")\n",
    "\n",
    "    auc, best_state, val_probs, val_emb = train_one_fold(\n",
    "        train_idx,\n",
    "        val_idx,\n",
    "        epochs=300,\n",
    "        lr=5e-3,\n",
    "        wd=1e-4\n",
    "    )\n",
    "\n",
    "    fold_aucs.append(auc)\n",
    "    fold_states.append(best_state)        # <-- SAVE MODEL\n",
    "    fold_splits.append((train_idx, val_idx))  # <-- SAVE SPLIT\n",
    "\n",
    "    oof_gnn[val_idx] = val_probs\n",
    "    oof_embs[val_idx]  = val_emb\n",
    "\n",
    "    print(f\"Fold {fold} best AUC: {auc:.5f}\")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"Fold AUCs:\", [f\"{a:.5f}\" for a in fold_aucs])\n",
    "print(\"Mean AUC :\", float(np.mean(fold_aucs)))\n",
    "print(\"OOF AUC  :\", float(roc_auc_score(data.y.cpu().numpy(), oof_gnn)))\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b50b2f-7795-4c0e-bfd4-cb11e2c0c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE GNN OOF\n",
    "np.save(f\"data/oof_preds_gnn_v{VER}\",oof_gnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b62199-e9a6-4b9a-80f8-e34aa88e918d",
   "metadata": {},
   "source": [
    "# Train XGB w/ GNN Embeddings\n",
    "We will now train XGB using GNN embeddings. This performs better than simple average of XGB and GNN probability predictions that was done in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cdec9b-dd29-4da3-bdd0-f8cd592c6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"n_estimators\": 10_000,\n",
    "    \"random_state\": 42,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"device\": \"cuda\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c52d3-345f-4b22-b368-2e08e4a4657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB version: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(f\"XGB version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659fecf-d857-4772-a31c-ee8b9a019e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### STACK FOLD 1 #####\n",
      "Fold 1 AUC: 0.75610\n",
      "\n",
      "##### STACK FOLD 2 #####\n",
      "Fold 2 AUC: 0.75643\n",
      "\n",
      "##### STACK FOLD 3 #####\n",
      "Fold 3 AUC: 0.76022\n",
      "\n",
      "##### STACK FOLD 4 #####\n",
      "Fold 4 AUC: 0.76307\n",
      "\n",
      "##### STACK FOLD 5 #####\n",
      "Fold 5 AUC: 0.75704\n",
      "\n",
      "==============================\n",
      "Fold AUCs: ['0.75610', '0.75643', '0.76022', '0.76307', '0.75704']\n",
      "Mean AUC : 0.7585728593018518\n",
      "OOF AUC  : 0.7585639778208273\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "from cuml.decomposition import PCA\n",
    "\n",
    "# tabular features\n",
    "X_tab = author_features[FEATURES].values.astype(np.float32)\n",
    "y = author_features[TARGET].values.astype(np.int64)\n",
    "\n",
    "N = len(y)\n",
    "oof_preds = np.zeros(N, dtype=np.float32)\n",
    "fold_scores = []\n",
    "\n",
    "# IMPORTANT: reuse the SAME splits as GNN training\n",
    "for fold, ((train_idx, val_idx), gnn_state) in enumerate(\n",
    "    zip(fold_splits, fold_states), 1\n",
    "):\n",
    "    print(f\"\\n##### STACK FOLD {fold} #####\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load fold-specific GNN\n",
    "    # -----------------------------\n",
    "    gnn = GraphSAGE(\n",
    "        in_dim=data.x.size(1),\n",
    "        hidden_dim=EMB_DIM,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    gnn.load_state_dict({k: v.to(device) for k, v in gnn_state.items()})\n",
    "    gnn.eval()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract embeddings (same space)\n",
    "    # -----------------------------\n",
    "    with torch.no_grad():\n",
    "        emb_all = gnn(\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            return_emb=True\n",
    "        ).cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # -----------------------------\n",
    "    # PCA on embeddings (FIT = train only)\n",
    "    # -----------------------------\n",
    "    pca = PCA(n_components=8)\n",
    "    emb_train_pca = pca.fit_transform(emb_all[train_idx])\n",
    "    emb_val_pca   = pca.transform(emb_all[val_idx])\n",
    "\n",
    "    # -----------------------------\n",
    "    # Build stacked features\n",
    "    # -----------------------------\n",
    "    X_train = np.hstack([\n",
    "        X_tab[train_idx],\n",
    "        emb_train_pca\n",
    "    ])\n",
    "\n",
    "    X_val = np.hstack([\n",
    "        X_tab[val_idx],\n",
    "        emb_val_pca\n",
    "    ])\n",
    "\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Train stack XGB (regularized!)\n",
    "    # -----------------------------\n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]\n",
    "    oof_preds[val_idx] = rankdata(val_preds)\n",
    "\n",
    "    auc = roc_auc_score(y_val, val_preds)\n",
    "    fold_scores.append(auc)\n",
    "\n",
    "    print(f\"Fold {fold} AUC: {auc:.5f}\")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"Fold AUCs:\", [f\"{s:.5f}\" for s in fold_scores])\n",
    "print(\"Mean AUC :\", np.mean(fold_scores))\n",
    "print(\"OOF AUC  :\", roc_auc_score(y, oof_preds))\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1530029-76d7-4671-83ba-f3ea4a4d1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE GNN OOF\n",
    "np.save(f\"data/oof_preds_xgb_gnn_v{VER}\",oof_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7fd27-4483-44a7-adee-cabeca8013f5",
   "metadata": {},
   "source": [
    "# Compare to Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cc216-938f-4052-9d13-8d5d3bd7145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB OOF AUC  : 0.755080970524253\n",
      "GNN OOF AUC  : 0.7556822341151668\n",
      "\n",
      "XGB GNN BLEND  : 0.7576088669046419\n",
      "XGB w/ GNN emb  : 0.7585639778208273\n"
     ]
    }
   ],
   "source": [
    "oof_xgb = np.load(f\"data/oof_preds_xgb_v{LOAD}.npy\")\n",
    "print(\"XGB OOF AUC  :\", float(roc_auc_score(author_features[TARGET].values, oof_xgb)))\n",
    "\n",
    "oof_gnn = np.load(f\"data/oof_preds_gnn_v{VER}.npy\")\n",
    "print(\"GNN OOF AUC  :\", float(roc_auc_score(author_features[TARGET].values, oof_gnn)))\n",
    "\n",
    "blend = (oof_xgb + oof_gnn)/2.\n",
    "print(\"XGB GNN BLEND  :\", float(roc_auc_score(author_features[TARGET].values, blend)))\n",
    "\n",
    "oof_xgb_gnn = np.load(f\"data/oof_preds_xgb_gnn_v{VER}.npy\")\n",
    "print(\"XGB w/ GNN emb  :\", float(roc_auc_score(author_features[TARGET].values, oof_xgb_gnn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
