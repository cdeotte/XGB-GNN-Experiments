{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9e0bba-b79e-4325-bfe3-f82bf41f7811",
   "metadata": {},
   "source": [
    "# Build GNN and Ensemble with XGB\n",
    "In this notebook we build a simple GNN model and combine it with XGB model to see if GNN improves XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711e5b1-0f28-471f-b889-1cd46fc4c735",
   "metadata": {},
   "source": [
    "# Simple GNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401f6dcc-853f-49f9-a70e-ccc18deb1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"7\")\n",
    "\n",
    "VER=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba98df61-5aac-44e3-9c8f-12c1e5d0a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02213d78-7c61-4579-ab9d-f95921d44167",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_features = pd.read_parquet(f\"data/author_features_v{VER}.pqt\")\n",
    "author_targets = pd.read_parquet(f\"data/author_targets_v{VER}.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7852e8aa-82c1-4e65-aef5-84edac567a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_ID</th>\n",
       "      <th>target</th>\n",
       "      <th>coauthor_ids</th>\n",
       "      <th>coauthor_counts</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 2905, 2819, 2906, 2907, ...</td>\n",
       "      <td>[1, 1, 1, 4, 4, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Author_ID  target                                       coauthor_ids  \\\n",
       "0          0       0                                                 []   \n",
       "1          1       0                              [2, 3, 4, 5, 6, 7, 8]   \n",
       "2          2       0                              [1, 3, 4, 5, 6, 7, 8]   \n",
       "3          3       0                              [1, 2, 4, 5, 6, 7, 8]   \n",
       "4          4       1  [1, 2, 3, 5, 6, 7, 8, 2905, 2819, 2906, 2907, ...   \n",
       "\n",
       "                                     coauthor_counts  degree  \n",
       "0                                                 []       0  \n",
       "1                              [1, 1, 1, 1, 1, 1, 1]       7  \n",
       "2                              [1, 1, 1, 1, 1, 1, 1]       7  \n",
       "3                              [1, 1, 1, 1, 1, 1, 1]       7  \n",
       "4  [1, 1, 1, 4, 4, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, ...      38  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdcbcf42-a74e-4ec0-8310-9803549f7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(author_features)\n",
    "assert author_features[\"Author_ID\"].is_unique\n",
    "\n",
    "id2idx = pd.Series(np.arange(N), index=author_features[\"Author_ID\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6aa8132-b791-4d87-8777-1ef826b2fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG TRANSFORM FOR NN\n",
    "for c in [\n",
    "    \"n_coauthors\",\n",
    "    \"total_collaborations\",\n",
    "    \"total_papers\",\n",
    "    \"total_citations\",\n",
    "    \"citations_last_3y\",\n",
    "    \"max_citations_single_paper\",\n",
    "]:\n",
    "    author_features[f\"log_{c}\"] = np.log1p(author_features[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c44f22-5cd7-49bf-ba1a-1e9159d3660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['n_coauthors', 'total_collaborations', 'avg_collab_strength', 'max_collab_strength', 'collab_entropy', 'total_papers', 'papers_last_1y', 'papers_last_3y', 'days_since_last_paper', 'top_category_frac', 'category_entropy', 'total_citations', 'avg_citations_per_paper', 'max_citations_single_paper', 'citations_last_3y', 'log_n_coauthors', 'log_total_collaborations', 'log_total_papers', 'log_total_citations', 'log_citations_last_3y', 'log_max_citations_single_paper']\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"target\"\n",
    "\n",
    "BASE_FEATURES = [\n",
    "    # --------------------\n",
    "    # Collaboration graph\n",
    "    # --------------------\n",
    "    \"n_coauthors\",\n",
    "    \"total_collaborations\",\n",
    "    \"avg_collab_strength\",\n",
    "    \"max_collab_strength\",\n",
    "    \"collab_entropy\",\n",
    "\n",
    "    # --------------------\n",
    "    # Productivity / recency\n",
    "    # --------------------\n",
    "    \"total_papers\",\n",
    "    \"papers_last_1y\",\n",
    "    \"papers_last_3y\",\n",
    "    \"days_since_last_paper\",\n",
    "\n",
    "    # --------------------\n",
    "    # Topic specialization\n",
    "    # --------------------\n",
    "    #\"top_category\",          # categorical-as-ordinal (needs encoding for NN)\n",
    "    \"top_category_frac\",\n",
    "    \"category_entropy\",\n",
    "\n",
    "    # --------------------\n",
    "    # Citation impact\n",
    "    # --------------------\n",
    "    \"total_citations\",\n",
    "    \"avg_citations_per_paper\",\n",
    "    \"max_citations_single_paper\",\n",
    "    \"citations_last_3y\",\n",
    "]\n",
    "\n",
    "EXTRA_FEATURES = [\n",
    "    \"log_n_coauthors\",\n",
    "    \"log_total_collaborations\",\n",
    "    \"log_total_papers\",\n",
    "    \"log_total_citations\",\n",
    "    \"log_citations_last_3y\",\n",
    "    \"log_max_citations_single_paper\",\n",
    "]\n",
    "\n",
    "FEATURES = [c for c in (BASE_FEATURES + EXTRA_FEATURES) if c in author_features.columns]\n",
    "print(\"Using features:\", FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83186e65-9524-420f-bd46-48e706fe101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = author_features[FEATURES].astype(np.float32).values\n",
    "y = author_features[TARGET].astype(np.int64).values\n",
    "\n",
    "# standardize\n",
    "X_mean = X.mean(axis=0, keepdims=True)\n",
    "X_std  = X.std(axis=0, keepdims=True) + 1e-6\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "x = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4982109-f4ff-4fad-9d3e-f9fe76e4b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure coauthor lists align to author_features order\n",
    "author_targets_aligned = author_targets.set_index(\"Author_ID\").loc[author_features[\"Author_ID\"]].reset_index()\n",
    "\n",
    "src_list = []\n",
    "dst_list = []\n",
    "w_list   = []\n",
    "\n",
    "for i, (co_ids, co_cts) in enumerate(\n",
    "    zip(author_targets_aligned[\"coauthor_ids\"], author_targets_aligned[\"coauthor_counts\"])\n",
    "):\n",
    "    # skip isolated authors\n",
    "    if len(co_ids) == 0:\n",
    "        continue\n",
    "\n",
    "    js = id2idx.loc[co_ids].values.astype(np.int64)\n",
    "    cts = np.asarray(co_cts, dtype=np.float32)\n",
    "\n",
    "    src_list.append(np.full(len(js), i, dtype=np.int64))\n",
    "    dst_list.append(js)\n",
    "    w_list.append(cts)\n",
    "\n",
    "src = np.concatenate(src_list) if src_list else np.empty(0, dtype=np.int64)\n",
    "dst = np.concatenate(dst_list) if dst_list else np.empty(0, dtype=np.int64)\n",
    "w   = np.concatenate(w_list)   if w_list   else np.empty(0, dtype=np.float32)\n",
    "\n",
    "edge_index = torch.tensor(np.vstack([src, dst]), dtype=torch.long)\n",
    "edge_weight = torch.tensor(w, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74fd37b-4d6d-4e8f-9a11-14e98d359388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num nodes: 143691\n",
      "Num edges (directed): 11182120\n"
     ]
    }
   ],
   "source": [
    "print(\"Num nodes:\", N)\n",
    "print(\"Num edges (directed):\", edge_index.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f6a8745-a02e-4129-a67f-348b1ef88680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "data.edge_weight = edge_weight  # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c91fccd-cfeb-4150-be47-714acfe39530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.lin   = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        out = self.lin(x).squeeze(-1)  # logits\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf992892-9326-48cb-9b6a-37779886e5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### FOLD 1 #####\n",
      "  epoch   1 | loss 0.7222 | val AUC 0.43801 | best 0.43801\n",
      "  epoch  30 | loss 0.5730 | val AUC 0.74629 | best 0.74629\n",
      "  epoch  60 | loss 0.5690 | val AUC 0.74853 | best 0.75065\n",
      "  epoch  90 | loss 0.5669 | val AUC 0.74952 | best 0.75204\n",
      "  epoch 120 | loss 0.5646 | val AUC 0.75032 | best 0.75204\n",
      "  epoch 150 | loss 0.5631 | val AUC 0.75117 | best 0.75251\n",
      "  epoch 180 | loss 0.5618 | val AUC 0.75053 | best 0.75251\n",
      "  epoch 210 | loss 0.5606 | val AUC 0.75101 | best 0.75261\n",
      "  epoch 240 | loss 0.5598 | val AUC 0.75169 | best 0.75261\n",
      "  epoch 270 | loss 0.5594 | val AUC 0.75093 | best 0.75302\n",
      "  epoch 300 | loss 0.5575 | val AUC 0.75091 | best 0.75314\n",
      "Fold 1 best AUC: 0.75314\n",
      "\n",
      "##### FOLD 2 #####\n",
      "  epoch   1 | loss 0.6815 | val AUC 0.60414 | best 0.60414\n",
      "  epoch  30 | loss 0.5733 | val AUC 0.74551 | best 0.74551\n",
      "  epoch  60 | loss 0.5688 | val AUC 0.74836 | best 0.75033\n",
      "  epoch  90 | loss 0.5667 | val AUC 0.74895 | best 0.75188\n",
      "  epoch 120 | loss 0.5649 | val AUC 0.75151 | best 0.75229\n",
      "  epoch 150 | loss 0.5631 | val AUC 0.75233 | best 0.75299\n",
      "  epoch 180 | loss 0.5621 | val AUC 0.75138 | best 0.75325\n",
      "  epoch 210 | loss 0.5616 | val AUC 0.75163 | best 0.75391\n",
      "  epoch 240 | loss 0.5594 | val AUC 0.75297 | best 0.75391\n",
      "  epoch 270 | loss 0.5588 | val AUC 0.75161 | best 0.75391\n",
      "  epoch 300 | loss 0.5570 | val AUC 0.75312 | best 0.75401\n",
      "Fold 2 best AUC: 0.75401\n",
      "\n",
      "##### FOLD 3 #####\n",
      "  epoch   1 | loss 0.7149 | val AUC 0.51513 | best 0.51513\n",
      "  epoch  30 | loss 0.5741 | val AUC 0.75139 | best 0.75221\n",
      "  epoch  60 | loss 0.5699 | val AUC 0.75267 | best 0.75469\n",
      "  epoch  90 | loss 0.5679 | val AUC 0.75501 | best 0.75526\n",
      "  epoch 120 | loss 0.5657 | val AUC 0.75499 | best 0.75658\n",
      "  epoch 150 | loss 0.5645 | val AUC 0.75546 | best 0.75726\n",
      "  epoch 180 | loss 0.5629 | val AUC 0.75629 | best 0.75781\n",
      "  epoch 210 | loss 0.5621 | val AUC 0.75501 | best 0.75781\n",
      "  epoch 240 | loss 0.5606 | val AUC 0.75615 | best 0.75781\n",
      "  epoch 270 | loss 0.5598 | val AUC 0.75643 | best 0.75781\n",
      "  epoch 300 | loss 0.5588 | val AUC 0.75792 | best 0.75819\n",
      "Fold 3 best AUC: 0.75819\n",
      "\n",
      "##### FOLD 4 #####\n",
      "  epoch   1 | loss 0.6946 | val AUC 0.57694 | best 0.57694\n",
      "  epoch  30 | loss 0.5750 | val AUC 0.75349 | best 0.75349\n",
      "  epoch  60 | loss 0.5711 | val AUC 0.75637 | best 0.75637\n",
      "  epoch  90 | loss 0.5692 | val AUC 0.75663 | best 0.75763\n",
      "  epoch 120 | loss 0.5672 | val AUC 0.75705 | best 0.75945\n",
      "  epoch 150 | loss 0.5654 | val AUC 0.75903 | best 0.75977\n",
      "  epoch 180 | loss 0.5647 | val AUC 0.75985 | best 0.76045\n",
      "  epoch 210 | loss 0.5642 | val AUC 0.75954 | best 0.76069\n",
      "  epoch 240 | loss 0.5629 | val AUC 0.75960 | best 0.76159\n",
      "  epoch 270 | loss 0.5612 | val AUC 0.75953 | best 0.76159\n",
      "  epoch 300 | loss 0.5603 | val AUC 0.75983 | best 0.76159\n",
      "Fold 4 best AUC: 0.76159\n",
      "\n",
      "##### FOLD 5 #####\n",
      "  epoch   1 | loss 0.6941 | val AUC 0.52385 | best 0.52385\n",
      "  epoch  30 | loss 0.5727 | val AUC 0.74906 | best 0.74939\n",
      "  epoch  60 | loss 0.5688 | val AUC 0.75343 | best 0.75343\n",
      "  epoch  90 | loss 0.5671 | val AUC 0.75359 | best 0.75359\n",
      "  epoch 120 | loss 0.5649 | val AUC 0.75267 | best 0.75458\n",
      "  epoch 150 | loss 0.5637 | val AUC 0.75244 | best 0.75481\n",
      "  epoch 180 | loss 0.5623 | val AUC 0.75476 | best 0.75582\n",
      "  epoch 210 | loss 0.5616 | val AUC 0.75494 | best 0.75632\n",
      "  epoch 240 | loss 0.5615 | val AUC 0.75515 | best 0.75690\n",
      "  epoch 270 | loss 0.5600 | val AUC 0.75420 | best 0.75690\n",
      "  epoch 300 | loss 0.5591 | val AUC 0.75601 | best 0.75690\n",
      "Fold 5 best AUC: 0.75690\n",
      "\n",
      "==============================\n",
      "Fold AUCs: ['0.75314', '0.75401', '0.75819', '0.76159', '0.75690']\n",
      "Mean AUC : 0.7567649803727108\n",
      "OOF AUC  : 0.7560026830991697\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = data.to(device)\n",
    "\n",
    "N_SPLITS = 5\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(N, dtype=np.float32)\n",
    "fold_aucs = []\n",
    "\n",
    "def train_one_fold(train_idx, val_idx, epochs=50, lr=1e-3, wd=1e-4):\n",
    "    model = GraphSAGE(in_dim=data.x.size(1), hidden_dim=128, dropout=0.1).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    train_mask = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "    val_mask   = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "    train_mask[torch.tensor(train_idx, device=device)] = True\n",
    "    val_mask[torch.tensor(val_idx, device=device)] = True\n",
    "\n",
    "    # BCE with logits\n",
    "    y_float = data.y.float()\n",
    "\n",
    "    best_auc = -1\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits[train_mask], y_float[train_mask])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # quick val AUC\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_probs = torch.sigmoid(logits[val_mask]).detach().cpu().numpy()\n",
    "            val_true  = data.y[val_mask].detach().cpu().numpy()\n",
    "            auc = roc_auc_score(val_true, val_probs)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        if epoch % 30 == 0 or epoch == 1:\n",
    "            print(f\"  epoch {epoch:3d} | loss {loss.item():.4f} | val AUC {auc:.5f} | best {best_auc:.5f}\")\n",
    "\n",
    "    # load best\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "\n",
    "    # final val preds\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        val_probs = torch.sigmoid(logits[val_mask]).detach().cpu().numpy()\n",
    "\n",
    "    return best_auc, val_probs\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(N)), 1):\n",
    "    print(f\"\\n##### FOLD {fold} #####\")\n",
    "    auc, val_probs = train_one_fold(train_idx, val_idx, epochs=300, lr=5e-3, wd=1e-4)\n",
    "    fold_aucs.append(auc)\n",
    "    oof_preds[val_idx] = val_probs\n",
    "    print(f\"Fold {fold} best AUC: {auc:.5f}\")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"Fold AUCs:\", [f\"{a:.5f}\" for a in fold_aucs])\n",
    "print(\"Mean AUC :\", float(np.mean(fold_aucs)))\n",
    "print(\"OOF AUC  :\", float(roc_auc_score(author_features[TARGET].values, oof_preds)))\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32aea4d7-7918-4aa2-8014-fbc14c20e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE GNN OOF\n",
    "np.save(f\"data/oof_preds_gnn_v{VER}\",oof_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eef272-061c-426d-b96e-cb4c6ca9fa95",
   "metadata": {},
   "source": [
    "# Ensemble XGB and GNN\n",
    "This is a simple experiment to see if using both XGB and GNN improves performance compared to using only one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d28d08-564a-49f3-a4e4-11d64b1ccd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB OOF AUC  : 0.755080970524253\n",
      "GNN OOF AUC  : 0.7560026830991697\n",
      "BLEND OOF AUC  : 0.7577506691419102\n"
     ]
    }
   ],
   "source": [
    "oof_xgb = np.load(f\"data/oof_preds_xgb_v{VER}.npy\")\n",
    "print(\"XGB OOF AUC  :\", float(roc_auc_score(author_features[TARGET].values, oof_xgb)))\n",
    "\n",
    "oof_gnn = np.load(f\"data/oof_preds_gnn_v{VER}.npy\")\n",
    "print(\"GNN OOF AUC  :\", float(roc_auc_score(author_features[TARGET].values, oof_gnn)))\n",
    "\n",
    "blend = (oof_xgb + oof_gnn)/2.\n",
    "print(\"BLEND OOF AUC  :\", float(roc_auc_score(author_features[TARGET].values, blend)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
